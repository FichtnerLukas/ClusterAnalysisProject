# -*- coding: utf-8 -*-
"""1. TravelTide_Clustering_ ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v6BCfBKxlCFDBeLQx7ox3igF2puFyGtN

## 1.Import Libraries and PostgreSQL database
"""

# Import necessary libraries for data analysis and database connection
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine
from geopy.distance import geodesic
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples

# PostreSQL connection parameters
username = 'Test'
password = 'bQNxVzJL4g6u'
host = 'ep-noisy-flower-846766.us-east-2.aws.neon.tech'
port = '5432'
database = 'TravelTide'

# Create connvection string using SQLAlchemy
conn_string = f'postgresql://{username}:{password}@{host}:{port}/{database}'
engine = create_engine(conn_string)

# Load data from database into pandas DataFrames
flights = pd.read_sql("SELECT * FROM flights", engine)
hotels = pd.read_sql("SELECT * FROM hotels", engine)
sessions = pd.read_sql("SELECT * FROM sessions", engine)
users = pd.read_sql("SELECT * FROM users", engine)

"""## 2.Filtering, Merging and Data Cleaning

### Filtering active users and merging tables
"""

# Filter sessions after 2023-01-04 to focus on recent activity
sessions_cleaned = sessions[sessions['session_start'] > '2023-01-04']

# Identify users with more than 7 sessions
user_session_counts = sessions_cleaned.groupby('user_id').size().reset_index(name='session_count')
filtered_users = user_session_counts[user_session_counts['session_count'] > 7]

# Filter sessions to include only active users
filtered_sessions = sessions_cleaned[sessions_cleaned['user_id'].isin(filtered_users['user_id'])]


# Merge sessions with users, flights, and hotels data
session_user = filtered_sessions.merge(users, on='user_id', how='left')
session_user_flight = session_user.merge(flights, on='trip_id', how='left')
session_base = session_user_flight.merge(hotels, on='trip_id', how='left')

# Rename column for clarity
session_base = session_base.rename(columns={'hotel_per_room_usd': 'hotel_price_per_room_night_usd'})

# Display shape of merged DataFrame
print(f"Merged DataFrame shape: {session_base.shape}")

"""### Data Cleaning"""

# Check for missing values
print("Missing values in each column:")
print(session_base.isna().sum())

columns_to_fill = [
    'flight_discount', 'hotel_discount', 'flight_discount_amount', 'hotel_discount_amount',
    'nights', 'rooms', 'hotel_price_per_room_night_usd', 'seats', 'checked_bags', 'base_fare_usd'
]
for col in columns_to_fill:
    session_base[col] = session_base[col].fillna(0)

# Verify unique home countries
session_base['home_country'].unique()

# For consistancy capitalize 'canada' and uppercase 'usa'
def apply_home_country(country):
    country = str(country).lower()
    if country == 'usa' or country == 'united states':
        return 'USA'
    else:
        return 'Canada'

session_base['home_country'] = session_base['home_country'].apply(apply_home_country)
session_base['home_country'].unique()

"""It was identified that for all entries with negative night values, the check_in and check_out dates were swapped. To resolve this, these entries have been corrected by swapping the dates back, and the nights have been recalculated accordingly."""

#change the check_in_time and check_out_time of bookings where nights have negative values and calculate the nights again
negative_nights = session_base['nights'] < 0
session_base.loc[negative_nights, ['check_in_time', 'check_out_time']] = \
    session_base.loc[negative_nights, ['check_out_time', 'check_in_time']].values

session_base['nights'] = (session_base['check_out_time'] - session_base['check_in_time']).dt.days.fillna(0)

"""## 3.Feature Engineering

### Flight based features
"""

#generated a distance by kilometer calculating the distance between lat/lon of destination - and home_airport
def calculate_distance(row):
    if pd.notna(row['destination_airport_lat']) and pd.notna(row['destination_airport_lon']):
        coord1 = (row['home_airport_lat'], row['home_airport_lon'])
        coord2 = (row['destination_airport_lat'], row['destination_airport_lon'])
        return geodesic(coord1, coord2).km
    else:
        return None

session_base["distance_flown_km"] = session_base.apply(calculate_distance, axis=1).fillna(0)

# sum flights
def sum_up_flights(row):
    if row['flight_booked'] == True and row['return_flight_booked'] == True:
        return 2
    elif row['flight_booked'] == True and row['return_flight_booked'] == False:
        return 1
    else:
        return 0

session_base['num_flights'] = session_base.apply(sum_up_flights, axis=1)

#sum how much money spent on flights
def money_spent_flights(row):
  if row['flight_discount'] == True:
    return row['base_fare_usd'] * row['num_flights'] * (1 - row['flight_discount_amount'])
  else:
    return row['base_fare_usd'] + row['num_flights']

session_base['money_spent_flights'] = session_base.apply(money_spent_flights, axis=1).fillna(0)

"""### Hotel based feature"""

#sum how much money spent on hotel
def money_spent_hotel(row):
  if row['hotel_discount'] == True:

    return (row['hotel_price_per_room_night_usd'] * row['nights'] * row['rooms']) * (1 - row['hotel_discount_amount'])
  else:
    return row['hotel_price_per_room_night_usd'] * row['nights'] * row['rooms']

session_base['money_spent_hotel'] = session_base.apply(money_spent_hotel, axis=1).fillna(0)

"""### Trip based features

"""

#calculate trip duration
def trip_calc(row):
  if pd.notna(row['departure_time']) and pd.notna(row['return_time']):
    return (row['return_time'] - row['departure_time']).days
  else:
    return (row['check_out_time'] - row['check_in_time']).days

session_base['trip_duration'] = session_base.apply(trip_calc, axis=1)

def money_spent_total(row):
    return row['money_spent_hotel'] + row['money_spent_flights']

session_base['money_spent_total'] = session_base.apply(money_spent_total, axis=1).fillna(0)

#Calculate the leadtime between booking and trip beginn

def leadtime(row):
    # Check if trip exists and flight was booked
    if pd.notna(row['trip_id']) and row['flight_booked']== True and row['cancellation'] == False:
        if pd.notna(row['departure_time']) and pd.notna(row['session_end']):
            return (row['departure_time'] - row['session_end']).days

    # Check if trip exists and hotel was booked (without flight)
    elif pd.notna(row['trip_id']) and not row['flight_booked'] and row['hotel_booked'] and row['cancellation'] == False:
        if pd.notna(row['check_in_time']) and pd.notna(row['session_end']):
            return (row['check_in_time'] - row['session_end']).days

    return None

session_base['leadtime_to_trip'] = session_base.apply(leadtime, axis=1).fillna(0)

"""### User based features"""

#filter valid sessions
valid_trip_ids = session_base.groupby('trip_id').first()
valid_trip_ids = np.array(valid_trip_ids[valid_trip_ids['cancellation'] == False].reset_index()['trip_id'])
print(f'valid trips {len(valid_trip_ids)}')
valid_trip_ids

#calcualte session duration
session_base['session_duration'] = (session_base['session_end'] - session_base['session_start']).dt.total_seconds()
#calculate age per user
session_base['age'] = (pd.to_datetime(session_base['session_end'].max()) - pd.to_datetime(session_base['birthdate'])).dt.days // 365

#Travel Type
def travel_type(row):
  if row['has_children'] == True and row['trip_duration'] > 6 and row['rooms'] > 1:
    return 'Family Trip'
  elif row['departure_time'].weekday() <5 and row['trip_duration'] <4  and row['hotel_booked'] == False and row['seats'] == 1 and row['num_flights'] > 1:
    return 'Business Trip'
  else:
    return 'Leisure'

session_base['travel_type'] = session_base.apply(travel_type, axis=1)

#aggragate user behavior into metrics
user_base_session = session_base.groupby('user_id').agg({
    'page_clicks': 'sum',
    'session_id': pd.Series.nunique,
    'session_duration': 'mean',
    'checked_bags': 'mean',
    'flight_discount_amount' : 'sum',
    'hotel_discount_amount' : 'sum'


}).reset_index()

# Rename columns to match SQL output
user_base_session.rename(columns={
    'page_clicks': 'num_clicks',
    'session_id': 'num_sessions',
    'session_duration': 'avg_session_duration',
    'checked_bags': 'avg_bags',
    'flight_discount_amount' : 'flight_discount_amount',
    'hotel_discount_amount' : 'hotel_discount_amount'


}, inplace=True)
print(user_base_session.shape)
user_base_session.head()

# Add computed columns before grouping
session_base_valid = session_base[session_base['trip_id'].isin(valid_trip_ids)].copy()
print(f'all sessions {session_base.shape[0]}, valid sessions {session_base_valid.shape[0]}')

session_base_valid['num_flights'] = session_base_valid.apply(sum_up_flights, axis=1)
session_base_valid['money_spent_hotel'] = session_base_valid.apply(money_spent_hotel, axis=1)
session_base_valid['avg_km_flown'] = session_base_valid.apply(calculate_distance, axis=1)
session_base_valid['time_after_booking'] = session_base_valid.apply(leadtime, axis=1)
session_base_valid['money_spent_flights'] = session_base_valid.apply(money_spent_flights, axis=1)
session_base_valid['money_spent_total'] = session_base_valid.apply(money_spent_total, axis=1)


session_base_valid['hotel_price_per_room_night_usd'] = session_base_valid['hotel_price_per_room_night_usd'].fillna(0)
session_base_valid['nights'] = session_base_valid['nights'].fillna(0)
session_base_valid['rooms'] = session_base_valid['rooms'].fillna(0)
session_base_valid['hotel_discount_amount'] = session_base_valid['hotel_discount_amount'].fillna(0)
session_base_valid['flight_discount_amount'] = session_base_valid['flight_discount_amount'].fillna(0)


# Now group by user_id
user_base_trip = session_base_valid.groupby('user_id').agg({
    'trip_id': pd.Series.nunique,
    'num_flights': 'sum',
    'money_spent_hotel': 'sum',
    'money_spent_flights': 'sum',
    'money_spent_total': 'sum',
    'nights': 'mean',
    'rooms': 'mean',
    'time_after_booking': 'mean',
    'avg_km_flown': 'mean',
    'trip_duration': 'mean'

}).reset_index()

print(user_base_trip.shape)
user_base_trip.head()

"""## 4.Exploratory data analysis (before clustering)

###User related
"""

# Count of users by home country
plt.figure(figsize=(12, 6))
sns.countplot(data=session_base, x='home_country', color='lightblue', order=session_base['home_country'].value_counts().index[:2])
plt.title('Home Countries of Users')
plt.xticks(rotation=45)
plt.ylabel('Number of Users')
plt.show()

#Grouping by age bins (the youngest user is 16 and the oldest is 88)
age_bins = session_base.groupby(['gender', pd.cut(session_base['age'],bins=[15,30,65,100])]).size().unstack()

# Calculate percentages relative to TOTAL users (grand sum)
total_users = age_bins.sum().sum()  # Grand total across all groups
age_bins_percent_total = (age_bins / total_users) * 100

print("\nCount of Users by Age Bin and Gender:")
print(age_bins)
print("\nPercentage Distribution by Gender in Each Age Bin:")
print(age_bins_percent_total.round(2).astype(str) + '%')


#Histogram age distribution by gender
sns.histplot(data=session_base, x='age', hue='gender',  kde=True)
plt.show()

"""### Correlations"""

# Compute correlation matrix
corr_matrix = session_base[['money_spent_total', 'money_spent_flights', 'money_spent_hotel', 'distance_flown_km']].corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix of Numerical Features')
plt.show()

"""## 5.Final dataset"""

# Merge user_base_session (b) with users (u)
merged = user_base_session.merge(users, on='user_id', how='left')

# Merge that with user_base_trip (t)
merged = merged.merge(user_base_trip, on='user_id', how='left')

# Fill nulls (COALESCE equivalent)
merged['num_clicks'] = merged['num_clicks'].fillna(0)
merged['num_sessions'] = merged['num_sessions'].fillna(0)
merged['avg_session_duration'] = merged['avg_session_duration'].fillna(0)
merged['avg_bags'] = merged['avg_bags'].fillna(0)
merged['num_trips'] = merged['trip_id'].fillna(0)
merged['num_flights'] = merged['num_flights'].fillna(0)
merged['nights'] = merged['nights'].fillna(0)
merged['rooms'] = merged['rooms'].fillna(0)
merged['money_spent_hotel'] = merged['money_spent_hotel'].fillna(0)
merged['money_spent_flights'] = merged['money_spent_flights'].fillna(0)
merged['money_spent_total'] = merged['money_spent_total'].fillna(0)
merged['time_after_booking'] = merged['time_after_booking'].fillna(0)
merged['avg_km_flown'] = merged['avg_km_flown'].fillna(0)
merged['trip_duration'] = merged['trip_duration'].fillna(0)
merged['hotel_discount_amount'] = merged['hotel_discount_amount'].fillna(0)
merged['flight_discount_amount'] = merged['flight_discount_amount'].fillna(0)
merged['age'] = merged['birthdate'].apply(lambda bd: datetime.now().year - bd.year if pd.notnull(bd) else 0)


# Select final columns (optional)
final_columns = [
    'user_id', 'num_clicks', 'num_sessions', 'avg_session_duration', 'time_after_booking',
    'num_trips', 'trip_duration', 'avg_bags', 'num_flights','rooms', 'nights', 'hotel_discount_amount', 'money_spent_hotel', 'money_spent_flights','flight_discount_amount', 'money_spent_total',
    'avg_km_flown','age', 'gender', 'married', 'has_children', 'home_country', 'home_city', 'home_airport',
]
final_df = merged[final_columns]

"""Code below to download a csv of the final_df for Tableau"""

#from google.colab import files
#final_df.to_csv('final_df.csv', encoding = 'utf-8-sig')
#files.download('final_df.csv')

"""## 6.K-Means Clustering"""

# Display the structure, data types, and non-null counts of the final DataFrame
final_df.info()

"""### Data Preprocessing"""

#Select and filtering numeric columns from the DataFrame (without ‘user_id’ and other non-numeric columns)
numeric_cols = final_df.select_dtypes(include=[np.number]).columns.tolist()
numeric_cols = [col for col in numeric_cols if col not in ['user_id', 'Unnamed: 0']]

#standardization of data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(final_df[numeric_cols])

#Reducing dimensionality to 2D using PCA for visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
final_df['pca1'] = X_pca[:, 0]
final_df['pca2'] = X_pca[:, 1]

# Evaluate optimal cluster count using silhouette score analysis
for n_clusters in range(2, 11):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(X_pca)
    score = silhouette_score(X_pca, clusters)
    print(f"Silhouette Score for {n_clusters} clusters: {score}")

"""**The silhouette score analysis across different cluster counts reveals minimal variation between configurations. While the scores show acceptable performance (avg 0.368), the marginal differences suggest limited distinction between cluster solutions.**"""

# Store the sum of squared distances (inertia) for different k values
inertias = []
k_values = range(1, 10)

for k in k_values:
    # Initialize KMeans with current k and a fixed random state for reproducibility
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_pca)  # Fit model to PCA-transformed data
    inertias.append(kmeans.inertia_)  # Append inertia (sum of squared distances)

# Plot the Elbow curve
plt.figure(figsize=(8, 5))
plt.plot(k_values, inertias, 'bo-', markersize=8, linewidth=2)
plt.xlabel('Number of Clusters (k)', fontsize=12)
plt.ylabel('Inertia (Sum of Squared Distances)', fontsize=12)
plt.title('Elbow Method for Optimal k in K-Means Clustering', fontsize=14, pad=20)
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(k_values)  # Ensure all k values are shown on x-axis
plt.show()

"""Based on the elbow method, the optimal number of clusters was determined to be five, where the normalized sum of squared distances (inertia) begins to plateau.

### K_Mean Clustering
"""

# Number of components for 95% variance
n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1
print(f"Optimal Number of components (95% variance): {n_components}")

#Clustering the data into 5 groups using K-Means (Requirement from the marketing department)
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

#create cluster column in final_dataframe
final_df['cluster'] = clusters

#Visualizing the clusters in a 2D PCA scatter plot
plt.figure(figsize=(10, 7))
plt.scatter(final_df['pca1'], final_df['pca2'], c=final_df['cluster'], cmap='viridis', alpha=0.6)
plt.title('Cluster Visualization (PCA reduced to 2D)')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.colorbar(label='Cluster')
plt.show()

#Displaying cluster centers in the original scale
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
cluster_centers_df = pd.DataFrame(cluster_centers, columns=numeric_cols)
print("Cluster centers (original scaling):")
print(cluster_centers_df)

#Counting the number of data points per cluster
print("\nNumber of users per cluster:")
print(final_df['cluster'].value_counts())

#Summarizing the average feature values for each cluster
for cluster_num in range(5):
    print(f"\nCluster {cluster_num} features:")
    cluster_data = final_df[final_df['cluster'] == cluster_num][numeric_cols]
    print(cluster_data.mean().sort_values(ascending=False))

"""Groups by Cluster:

**Cluster 0 = High-Spending, Long-Distance Frequent Flyers**
- Key Traits
 - Highest total spend (€13k+), especially on flights (€9.8k) and hotels (€3.1k).
 - Long-haul travelers (avg. 7,780 km flown).
 - Moderate engagement (clicks/sessions) but high trip frequency (2+ trips)

**Cluster 1 = Mid-Tier, Multi-Trip Travelers**
- Key Traits:
 -  Moderate spend (€4.3k), skewed toward hotels (€2.5k).
 - Shorter flights (2,127 km) but frequent trips (4+).
 - Older demographic (avg. age 45)

**Cluster 2 = Budget-Conscious, Infrequent Travelers**
- Key Traits:
 - Low spend (€2.2k), balanced between hotels (€1.5k) and flights (€691).
 - Short trips (5 days) with minimal discounts used.
 - Take fewer trips (1.99)

**Cluster 3 = Low-Engagement Occasional Travelers**
- Key Traits:
 - Minimal spend (€102), very short trips (0.45 days).
 - Low flight/hotel activity but high clicks (94/session).
 - Last-minute travel bookers, average lead time: 2 days

**Cluster 4 = Luxury Experience Seekers**
- Key Traits:
 - High spend (€5k) on hotels (€2.6k) and flights (€2.3k).
 - Long booking sessions (avg. 993 sec) and high clicks (363).
"""

final_df.describe()

"""## 7.Exploratory data analysis (after clustering)

### Cluster Profiles
"""

# Boxplot of total money spent by cluster
plt.figure(figsize=(10, 6))
sns.boxplot(data=final_df, x='cluster', y='money_spent_total', palette='Set2')
plt.title('Total Money Spent by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Total Money Spent (USD)')
plt.show()

# Bar plot of average trip duration by cluster
plt.figure(figsize=(10, 6))
sns.barplot(data=final_df, x='cluster', y='trip_duration', palette='Set3')
plt.title('Average Trip Duration by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Trip Duration (Days)')
plt.show()

"""### Flight discounts"""

# Histogram of flight discount amounts
plt.figure(figsize=(10, 6))
sns.histplot(data=final_df, x='flight_discount_amount', bins=30, kde=True, color='lightblue')
plt.title('Distribution of Flight Discount Amounts')
plt.xlabel('Flight Discount Amount')
plt.ylabel('Frequency')
plt.show()

# Scatter plot of money spent vs. discount amount
plt.figure(figsize=(10, 6))
sns.scatterplot(data=final_df, x='flight_discount_amount', y='money_spent_flights', hue='cluster', palette='Set2')
plt.title('Flight Spending vs. Discount Amount by Cluster')
plt.xlabel('Flight Discount Amount')
plt.ylabel('Money Spent on Flights (USD)')
plt.show()

"""### Flight discounts"""

# Histogram of flight discount amounts
plt.figure(figsize=(10, 6))
sns.histplot(data=final_df, x='hotel_discount_amount', bins=30, kde=True, color='lightblue')
plt.title('Distribution of Hotel Discount Amounts')
plt.xlabel('Hotel Discount Amount')
plt.ylabel('Frequency')
plt.show()

# Scatter plot of money spent vs. discount amount
plt.figure(figsize=(10, 6))
sns.scatterplot(data=final_df, x='hotel_discount_amount', y='money_spent_hotel', hue='cluster', palette='Set2')
plt.title('Hotel Spending vs. Discount Amount by Cluster')
plt.xlabel('Hotel Discount Amount')
plt.ylabel('Money Spent on Hotels (USD)')
plt.show()

"""### Outlier detection by km flown"""

# Boxplot to detect outliers in average km flown
plt.figure(figsize=(10, 6))
sns.boxplot(data=final_df, y='avg_km_flown', color='lightblue')
plt.title('Boxplot of Average Distance Flown')
plt.ylabel('Average Distance Flown (km)')
plt.show()

"""### Total Spending by Gender and Marital Status"""

# Bar plot of average money spent by marital status and gender
plt.figure(figsize=(10, 6))
sns.barplot(data=final_df, x='gender', y='money_spent_total', hue='married', palette='Set2')
plt.title('Average Total Spending by Gender and Marital Status')
plt.xlabel('Gender')
plt.ylabel('Total Money Spent (USD)')
plt.legend(title='Married')
plt.show()

